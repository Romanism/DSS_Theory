{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 최적화 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측 문제의 최종 목표는 실제 출력값(target)과 가장 유사한 출력하는 모형을 찾는 것\n",
    "- 즉, 예측 오차를 최소화 하는 예측 모형을 갖는 것이 목표이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{y} = g(x) = w_1 x_1 +  w_2 x_2 + \\ldots +  w_N x_N  = w^T x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측모형에서 우리가 결정할 수 있는건 $w_n$(모수, parameter)\n",
    "- 모수 설정에 따라 오차가 클수도, 작을수도 있기 때문에 모수 설정이 매우 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{모수 } w  \\;\\; \\xrightarrow{f} \\;\\; \\text{예측 오차의 크기 } e^Te  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측오차를 최소화하는 입력값을 찾는 문제를 최적화(Optimization)문제라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 최적화 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 $f$의 값을 최소화하는 변수 $x$의 값 $x^{\\ast}$를 찾는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x^{\\ast} = \\arg \\min_x f(x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최대화 문제는 $f(x)$를 $-f(x)$로 바꾸면 풀 수 있기에 보통 최소화만 고려\n",
    "- 목적함수(objective function), 비용함수(cost function), 손실함수(loss function) 등으로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 그리드 서치와 수치적 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 그리드 서치 (grid search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가능한 $x$의 값을 여러 개 넣어보고 그 중 가장 작은 값을 선택하는 것\n",
    "- 장점 : 최적화 문제를 푸는 가장 간단한 방법\n",
    "- 단점 : 많은 $x$위치에 대해 목적 함수 값을 계산해야 함 (많은 계산량 요구) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) 수치적 최적화 (numerical optimization)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 함수 위치가 최적점이 될 때까지 가능한 적은 횟수만큼 $x$위치를 옮기는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 필요한 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어떤 위치 $x_k$를 시도한 뒤, 다음 번에 시도할 위치 $x_{k+1}$을 찾는 알고리즘\n",
    "- 현재 위치 $x_k$가 최적점인지 판단하는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 알고리즘 아이디어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 현재 위치가 최적점인지 찾는 방법은 도함수 값이 0이라는 아이디어를 이용\n",
    "- 기울기가 0이라고 반드시 최소점이 되지는 않음\n",
    "- 모든 최소점은 기울기가 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SGD (Steepest Gradient Descent) 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 위치에서 기울기 값($g(x_k)$)만을 이용해 다음 시도할 위치를 찾아내는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_{k+1} = x_{k} - \\mu \\nabla f(x_k) = x_{k} - \\mu g(x_k)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 현재 위치에서 기울기가 음수(곡면이 아래로 향함)이면 앞으로 진행\n",
    "- 현재 위치에서 기울기가 양수(곡면이 위로 향함)이면 뒤로 진행\n",
    "- 현재 위치에서 기울기가 0이면 최적점으로 간주하고 옮기지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SciPy를 이용한 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SciPy의 optimize 서브 패키지는 최적화 명령 minimize를 제공\n",
    "- 디폴트 알고리즘은 BFGS방법\n",
    "- minimize명령은 최적화하고자 하는 함수와 최적화를 시작할 초기값을 인수로 받음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) minimize : 최적화 결과를 OptimizeResult 클래스 객체로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table-bordered\" style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>**속성**</td>\n",
    "    <td>**의미**</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>x</td>\n",
    "    <td>최적화 해</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>success</td> \n",
    "    <td>최적화 성공하면 True 반환</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>status</td> \n",
    "    <td>종료 상태. 최적화에 성공하면 0 반환</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>message</td> \n",
    "    <td>메세지 문자열</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>fun</td> \n",
    "    <td>x 위치에서의 함수 값</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>jac</td> \n",
    "    <td>x 위치에서의 자코비안(그레디언트) 벡터의 값</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>hess</td> \n",
    "    <td>x 위치에서의 헤시안 행렬의 값 </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>nfev</td> \n",
    "    <td>목적함수 호출 횟수</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>njev</td> \n",
    "    <td>자코비안 계산 횟수</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>nhev</td> \n",
    "    <td>헤시안 계산 횟수</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>nit</td> \n",
    "    <td>x 이동 횟수</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
